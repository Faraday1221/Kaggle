{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Ghouls, i.e. Majority Voting\n",
    "This is the last thing I tried as part of this competition. This notebook is going to compare a bunch of different models. Then Implement a Majority Vote Classifier. Heres what we want to try\n",
    "\n",
    "- SVM\n",
    "- KNN\n",
    "- RandomForest\n",
    "- OLS\n",
    "\n",
    "It is important to note that the MajorityVoteClassifier used here is from Python Machine Learning and is available as a built-in in sklearn as VotingClassifier. This notebook is my first attempt at this kind of classifier (outside of a RandomForest). **Although it is not implemented, this would have been a good place to try out the bias / variance method of testing our Classifier**.\n",
    "\n",
    "### A note on Pipelines\n",
    "I also tried building out big pipelines here as a way to make all of this easier. **Ultimately I wanted to build a single pipeline that fed all my individual models to a single Majority Voting classifier at the end of the pipe but didn't get the implementation right. I would also have liked to use predict for the weights in the Majority Voting Classifier but didn't get that to work either**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class ColumnExtractor(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"takes in a dataframe, parses it by columns and returns an np array\"\"\"\n",
    "    def __init__(self, columns=[]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.columns]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GetDummies(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"I hate LabelEncoder and OneHotEncoder this is my workaround\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "#         self.columns = columns\n",
    "        \n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "#         return pd.get_dummies(X[self.columns]).values #this assumed we were passing in a df, X is a np array\n",
    "        return pd.get_dummies(X).values\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p.205 from Python Machine Learning\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class MajorityVoteClassifier(BaseEstimator,ClassifierMixin):\n",
    "    \"\"\" A majority vote ensemble classifier\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    classifiers : array-like, shape = [n_classifiers] \n",
    "      Different classifiers for the ensemble\n",
    "    \n",
    "    vote : str, {'classlabel','probability}\n",
    "      Default: 'classlabel'\n",
    "      If 'classlabel' the prediction is based on \n",
    "      the argmax of class labels. Else if\n",
    "      'probability', the argmax of the sum of\n",
    "      probabilities is used to predict the class label\n",
    "      (recommended for calibrated classifiers)\n",
    "    \n",
    "    weights : array-like, shape = [n_classifiers]\n",
    "      Optional, default: None\n",
    "      If a list of 'int' or 'float' values are\n",
    "      provided, the classifiers are weighted by\n",
    "      importance; uses uniform weights if 'weights=None\n",
    "    \"\"\"\n",
    "    def __init__(self, classifiers, vote='classlabel',weights=None):\n",
    "        \n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers = {key: value \n",
    "                                  for key, value in \n",
    "                                  _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit classifiers.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix},\n",
    "            shape = [n_samples, n_features]\n",
    "            Matrix of training samples.\n",
    "            \n",
    "        y : array-like, shape = [n_samples]\n",
    "            Vector of target class labels.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "        # Use LabelEncoder to ensure class labels start\n",
    "        # with 0, which is important for np.argmax\n",
    "        # call in self.predict\n",
    "        self.labelenc_ = LabelEncoder()\n",
    "        self.labelenc_.fit(y)\n",
    "        self.classes_ = self.labelenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X,\n",
    "                                       self.labelenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels for X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix},\n",
    "            Shape = [n_samples, n_features]\n",
    "            Matrix of training samples.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        maj_vote : array-like, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "            \n",
    "        \"\"\"\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X),axis=1)\n",
    "            \n",
    "        else: # 'classlabel' vote\n",
    "            # Collect results from clf.predict calls\n",
    "            predictions = np.asarray([clf.predict(X)\n",
    "                                    for clf in \n",
    "                                    self.classifiers_]).T\n",
    "            maj_vote = np.apply_along_axis(\n",
    "                            lambda x:\n",
    "                            np.argmax(np.bincount(x,weights=self.weights)),\n",
    "                                                 axis=1,\n",
    "                                                 arr=predictions)\n",
    "        maj_vote = self.labelenc_.inverse_transform(maj_vote)\n",
    "        return maj_vote\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\" Predict class probabilities for X\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix},\n",
    "            shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is\n",
    "            the number of samples and\n",
    "            n_features is the number of features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        avg_proba : array-like\n",
    "            shape = [n_samples, n_classes]\n",
    "            Weighted average probability for\n",
    "            each class per sample.\n",
    "        \"\"\"\n",
    "        probas = np.asarray([clf.predict_proba(X) for clf in self.classifiers_])\n",
    "        \n",
    "        avg_proba = np.average(probas, axis=0, weights=self.weights)\n",
    "\n",
    "        return avg_proba\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"Get classifier parameter names for GridSearch\"\"\"\n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier, \n",
    "                         self).get_params(deep=False)\n",
    "        else:\n",
    "            out = self.named_classifiers.copy()\n",
    "            for name, step in sixiteritems(self.named_classifiers):\n",
    "                for key, value in six.iteritems(step.get_params(deep=True)):\n",
    "                    out['%s__%s' % (name, key)] = value\n",
    "            return out\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a quick test of the above\n",
    "x = GetDummies()\n",
    "x.fit_transform(train.color.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we see that our little categorical pipeline works as intended\n",
    "x = ColumnExtractor(['color'])\n",
    "y = GetDummies()\n",
    "\n",
    "xx = x.fit_transform(train)\n",
    "y.fit_transform(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = SVC()\n",
    "z.fit(y.fit_transform(xx), train.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'bone_length', 'rotting_flesh', 'hair_length', 'has_soul',\n",
       "       'color', 'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # a quick refresh of OneHotEncoder\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# # first we have to encode our categorical data\n",
    "# color_le = LabelEncoder()\n",
    "# X = color_le.fit_transform(train.color.values)\n",
    "\n",
    "# # # then we encode dummy columns\n",
    "# ohe = OneHotEncoder(sparse=False)\n",
    "# XX =  ohe.fit_transform(X).tolist()\n",
    "# XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "This is our pilot for a fancy pipeline we want the following:\n",
    "- continuous features\n",
    "    - extract continuous columns\n",
    "    - make a polynomial\n",
    "- categorical features\n",
    "    - extract categorical columns\n",
    "    - convert to binary indicators in seperate columns (i.e. pd.get_dummies)\n",
    "- call an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a fancy pipeline\n",
    "\"\"\"note since the first thing we do is extract features we pass in X as a dataframe and Y as a np array when fitting\"\"\"\n",
    "\n",
    "cont_cols = ['bone_length', 'rotting_flesh', 'hair_length', 'has_soul']\n",
    "cat_cols =  ['color']\n",
    "\n",
    "pipe_svm = Pipeline([('features',FeatureUnion([\n",
    "                          ('f_cont',Pipeline([\n",
    "                                ('extract',ColumnExtractor(cont_cols)),\n",
    "                                ('poly',PolynomialFeatures())])),\n",
    "#                           ('f_cat',Pipeline([\n",
    "#                                 ('extract',ColumnExtractor(cat_cols)),\n",
    "#                                 ('dummies',GetDummies())]))\n",
    "                           ])),\n",
    "                     ('clf',SVC(random_state=1))\n",
    "                    ])\n",
    "\n",
    "# pipe_svm.fit(train, train.type.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pipe_svm.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we can train this using GridSearchCV we are basically where we want to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GridSearch to determine best parameters\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "param_grid = [{'features__f_cont__poly__degree':[2,3],\n",
    "               'clf__C': param_range,\n",
    "               'clf__kernel': ['linear']},\n",
    "              {'features__f_cont__poly__degree':[2,3],\n",
    "               'clf__C': param_range,\n",
    "               'clf__gamma': param_range,\n",
    "               'clf__kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_svm,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=4,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 112 candidates, totalling 448 fits\n",
      "0.765498652291\n",
      "{'features__f_cont__poly__degree': 2, 'clf__C': 1.0, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 448 out of 448 | elapsed:   10.0s finished\n"
     ]
    }
   ],
   "source": [
    "gs.fit(train.drop(['id'],axis=1),train.type.values)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "\n",
    "# Error: AttributeError: 'ColumnExtractor' object has no attribute 'get_params'\n",
    "# we can fix this with the BaseEstimator class\n",
    "# http://stackoverflow.com/questions/27810855/python-sklearn-how-to-pass-parameters-to-the-customize-modeltransformer-clas\n",
    "\n",
    "# ANOTHER LESS OBVIOUS ERROR IS x.shape[1] = 20 is not equal to 21 the number of features at training time\n",
    "# this is the result of the get dummies where if a color isn't in the training sample it is dropped and there is 1 less feature\n",
    "# this is clearly an issue - it also rasies the question of weather or not our get dummies is generating columns\n",
    "# reliabily and repeatably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.765 +/- 0.015\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=gs.best_estimator_, X=train, y=train.type.values, cv=4, scoring='accuracy')\n",
    "print('Accuracy: {0:.3f} +/- {1:.3f}'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont_cols = ['bone_length', 'rotting_flesh', 'hair_length', 'has_soul']\n",
    "cat_cols =  ['color']\n",
    "\n",
    "pipe_knn = Pipeline([('features',FeatureUnion([\n",
    "                          ('f_cont',Pipeline([\n",
    "                                ('extract',ColumnExtractor(cont_cols)),\n",
    "                                ('poly',PolynomialFeatures())])),\n",
    "#                           ('f_cat',Pipeline([\n",
    "#                                 ('extract',ColumnExtractor(cat_cols)),\n",
    "#                                 ('dummies',GetDummies())]))\n",
    "                           ])),\n",
    "                     ('clf',KNeighborsClassifier())\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GridSearch to determine best parameters\n",
    "param_range = [2,3,4,5,6,7,8,9]\n",
    "param_grid = [{'features__f_cont__poly__degree':[2,3],\n",
    "               'clf__n_neighbors': param_range,\n",
    "               'clf__weights': ['uniform','distance']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_knn,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=4,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 32 candidates, totalling 128 fits\n",
      "0.746630727763\n",
      "{'clf__weights': 'uniform', 'features__f_cont__poly__degree': 3, 'clf__n_neighbors': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 128 out of 128 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "gs.fit(train.drop(['id'],axis=1),train.type.values)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.746 +/- 0.029\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=gs.best_estimator_, X=train, y=train.type.values, cv=4, scoring='accuracy')\n",
    "print('Accuracy: {0:.3f} +/- {1:.3f}'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_cols = ['bone_length', 'rotting_flesh', 'hair_length', 'has_soul']\n",
    "cat_cols =  ['color']\n",
    "\n",
    "pipe_rfc = Pipeline([('features',FeatureUnion([\n",
    "                          ('f_cont',Pipeline([\n",
    "                                ('extract',ColumnExtractor(cont_cols)),\n",
    "                                ('poly',PolynomialFeatures())])),\n",
    "#                           ('f_cat',Pipeline([\n",
    "#                                 ('extract',ColumnExtractor(cat_cols)),\n",
    "#                                 ('dummies',GetDummies())]))\n",
    "                           ])),\n",
    "                     ('clf',RandomForestClassifier(random_state=1))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GridSearch to determine best parameters\n",
    "\n",
    "param_grid = [{'features__f_cont__poly__degree':[2,3],\n",
    "               'clf__n_estimators': [5,10,15,20,25],\n",
    "               'clf__criterion': ['gini','entropy'],\n",
    "               'clf__min_samples_split': [2,4,6,8,10],\n",
    "               'clf__max_features': [2,4,6,8,10,'log2','sqrt']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_rfc,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=4,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 700 candidates, totalling 2800 fits\n",
      "0.743935309973\n",
      "{'clf__min_samples_split': 10, 'clf__criterion': 'entropy', 'features__f_cont__poly__degree': 3, 'clf__max_features': 4, 'clf__n_estimators': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2800 out of 2800 | elapsed:  2.8min finished\n"
     ]
    }
   ],
   "source": [
    "# scores without the color features\n",
    "gs.fit(train.drop(['id'],axis=1),train.type.values)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.744 +/- 0.013\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=gs.best_estimator_, X=train, y=train.type.values, cv=4, scoring='accuracy')\n",
    "print('Accuracy: {0:.3f} +/- {1:.3f}'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 700 candidates, totalling 2800 fits\n",
      "0.746630727763\n",
      "{'clf__min_samples_split': 6, 'clf__criterion': 'gini', 'features__f_cont__poly__degree': 3, 'clf__max_features': 2, 'clf__n_estimators': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2800 out of 2800 | elapsed:  3.1min finished\n"
     ]
    }
   ],
   "source": [
    "# scores for with color\n",
    "gs.fit(train.drop(['id'],axis=1),train.type.values)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.747 +/- 0.010\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=gs.best_estimator_, X=train, y=train.type.values, cv=4, scoring='accuracy')\n",
    "print('Accuracy: {0:.3f} +/- {1:.3f}'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_cols = ['bone_length', 'rotting_flesh', 'hair_length', 'has_soul']\n",
    "cat_cols =  ['color']\n",
    "\n",
    "pipe_lrc = Pipeline([('features',FeatureUnion([\n",
    "                          ('f_cont',Pipeline([\n",
    "                                ('extract',ColumnExtractor(cont_cols)),\n",
    "                                ('poly',PolynomialFeatures())])),\n",
    "                          ('f_cat',Pipeline([\n",
    "                                ('extract',ColumnExtractor(cat_cols)),\n",
    "                                ('dummies',GetDummies())]))\n",
    "                           ])),\n",
    "                     ('clf',LogisticRegression(random_state=1))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GridSearch to determine best parameters\n",
    "\n",
    "param_grid = [{'features__f_cont__poly__degree':[2,3],\n",
    "               'clf__penalty': ['l2'],\n",
    "               'clf__C': [0.001,0.01,0.1,1.0,10.0,100.0,1000.0],\n",
    "               'clf__class_weight': [None,'balanced'],\n",
    "               'clf__solver': ['liblinear','newton-cg','lbfgs']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_lrc,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=4,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 84 candidates, totalling 336 fits\n",
      "0.749326145553\n",
      "{'features__f_cont__poly__degree': 3, 'clf__solver': 'newton-cg', 'clf__penalty': 'l2', 'clf__C': 100.0, 'clf__class_weight': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 336 out of 336 | elapsed:   18.2s finished\n"
     ]
    }
   ],
   "source": [
    "gs.fit(train.drop(['id'],axis=1),train.type.values)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.749 +/- 0.020\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=gs.best_estimator_, X=train, y=train.type.values, cv=4, scoring='accuracy')\n",
    "print('Accuracy: {0:.3f} +/- {1:.3f}'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Vote Classifier\n",
    "We are going to implement a simple majority vote classifier - straight from the pages of Python Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_cols = ['bone_length', 'rotting_flesh', 'hair_length', 'has_soul']\n",
    "cat_cols =  ['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.749 +/- 0.063\n"
     ]
    }
   ],
   "source": [
    "# we will implement a series of classifiers\n",
    "# {'features__f_cont__poly__degree': 2, 'clf__C': 1.0, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}\n",
    "pipe_svm = Pipeline([('features',FeatureUnion([\n",
    "                          ('f_cont',Pipeline([\n",
    "                                ('extract',ColumnExtractor(cont_cols)),\n",
    "                                ('poly',PolynomialFeatures(degree=2))])),\n",
    "#                           ('f_cat',Pipeline([\n",
    "#                                 ('extract',ColumnExtractor(cat_cols)),\n",
    "#                                 ('dummies',GetDummies())]))\n",
    "                           ])),\n",
    "                     ('clf',SVC(C=1.0,gamma=0.1,kernel='rbf',random_state=1))\n",
    "                    ])\n",
    "scores = cross_val_score(pipe_svm,train,train.type.values,cv=10)\n",
    "print('Accuracy: {0:.3f} +/- {1:.3f}'.format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.719 +/- 0.045\n"
     ]
    }
   ],
   "source": [
    "# {'clf__weights': 'uniform', 'features__f_cont__poly__degree': 3, 'clf__n_neighbors': 8}\n",
    "pipe_knn = Pipeline([('features',FeatureUnion([\n",
    "                          ('f_cont',Pipeline([\n",
    "                                ('extract',ColumnExtractor(cont_cols)),\n",
    "                                ('poly',PolynomialFeatures(degree=3))])),\n",
    "#                           ('f_cat',Pipeline([\n",
    "#                                 ('extract',ColumnExtractor(cat_cols)),\n",
    "#                                 ('dummies',GetDummies())]))\n",
    "                           ])),\n",
    "                     ('clf',KNeighborsClassifier(weights='uniform',\n",
    "                                                 n_neighbors=8))\n",
    "                    ])\n",
    "scores = cross_val_score(pipe_knn,train,train.type.values,cv=10)\n",
    "print('Accuracy: {0:.3f} +/- {1:.3f}'.format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.711 +/- 0.054\n"
     ]
    }
   ],
   "source": [
    "# {'clf__min_samples_split': 10, 'clf__criterion': 'entropy', \n",
    "#  'features__f_cont__poly__degree': 3, 'clf__max_features': 4, 'clf__n_estimators': 20}\n",
    "pipe_rfc = Pipeline([('features',FeatureUnion([\n",
    "                          ('f_cont',Pipeline([\n",
    "                                ('extract',ColumnExtractor(cont_cols)),\n",
    "                                ('poly',PolynomialFeatures(degree=3))])),\n",
    "#                           ('f_cat',Pipeline([\n",
    "#                                 ('extract',ColumnExtractor(cat_cols)),\n",
    "#                                 ('dummies',GetDummies())]))\n",
    "                           ])),\n",
    "                     ('clf',RandomForestClassifier(min_samples_split=10,\n",
    "                                                   criterion='entropy',\n",
    "                                                   max_features=4,\n",
    "                                                   n_estimators=20,\n",
    "                                                   random_state=1))\n",
    "                    ])\n",
    "scores = cross_val_score(pipe_rfc,train,train.type.values,cv=10)\n",
    "print('Accuracy: {0:.3f} +/- {1:.3f}'.format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.735 +/- 0.053\n"
     ]
    }
   ],
   "source": [
    "# {'features__f_cont__poly__degree': 3, 'clf__solver': 'newton-cg', \n",
    "#  'clf__penalty': 'l2', 'clf__C': 100.0, 'clf__class_weight': None}\n",
    "pipe_lrc = Pipeline([('features',FeatureUnion([\n",
    "                          ('f_cont',Pipeline([\n",
    "                                ('extract',ColumnExtractor(cont_cols)),\n",
    "                                ('poly',PolynomialFeatures(degree=3))])),\n",
    "#                           ('f_cat',Pipeline([\n",
    "#                                 ('extract',ColumnExtractor(cat_cols)),\n",
    "#                                 ('dummies',GetDummies())]))\n",
    "                           ])),\n",
    "                     ('clf',LogisticRegression(solver = 'newton-cg',\n",
    "                                               class_weight = None,\n",
    "                                               penalty = 'l2',\n",
    "                                               C = 100.0,\n",
    "                                               random_state=1))\n",
    "                    ])\n",
    "\n",
    "scores = cross_val_score(pipe_lrc,train, train.type.values, cv=10)\n",
    "print('Accuracy: {0:.3f} +/- {1:.3f}'.format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Majority Vote Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.757 +/- 0.032 SVM\n",
      "Accuracy: 0.720 +/- 0.062 KNN\n",
      "Accuracy: 0.690 +/- 0.041 RFC\n",
      "Accuracy: 0.747 +/- 0.031 LRC\n",
      "Accuracy: 0.752 +/- 0.035 Majority Voting\n"
     ]
    }
   ],
   "source": [
    "mv_clf = MajorityVoteClassifier(classifiers=[pipe_svm,pipe_knn,pipe_rfc,pipe_lrc],\n",
    "                               weights=[.4,.2,.1,.3],\n",
    "                               vote='classlabel')\n",
    "\n",
    "clf_labels = ['SVM','KNN','RFC','LRC','Majority Voting']\n",
    "all_clf = [pipe_svm,pipe_knn,pipe_rfc,pipe_lrc,mv_clf]\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                            X=train.drop(['id'],axis=1),\n",
    "                            y=train.type.values,\n",
    "                            cv=5,\n",
    "                            scoring='accuracy')\n",
    "    print('Accuracy: {0:.3f} +/- {1:.3f} {2}'.format(scores.mean(),scores.std(),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.757 +/- 0.009\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(mv_clf,train.drop(['id'],axis=1),train.type.values,cv=4)\n",
    "print('Accuracy: {0:.3f} +/- {1:.3f}'.format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ghoul', 'Goblin', 'Ghoul', 'Ghost', 'Ghost', 'Ghost', 'Ghoul',\n",
       "       'Ghoul', 'Goblin', 'Ghoul'], dtype=object)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see how this does predicting our Ghosts\n",
    "mv_clf.fit(X=train,y=train.type.values)\n",
    "\n",
    "mv_pred = mv_clf.predict(test)\n",
    "mv_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Ghoul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Goblin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Ghoul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Ghost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>Ghost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    type\n",
       "0   3   Ghoul\n",
       "1   6  Goblin\n",
       "2   9   Ghoul\n",
       "3  10   Ghost\n",
       "4  13   Ghost"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id':test.id,'type':mv_pred})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission.to_csv('ghouls_mvc.csv',index=False)\n",
    "# .737157 not an improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Big Pipe\n",
    "Because fuck it - why not (apparently I just need to say Fuck it more because those are my best 2 submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelTransformer(TransformerMixin,BaseEstimator):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        self.model.fit(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return DataFrame(self.model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_big = Pipeline([('features',FeatureUnion([\n",
    "                          ('f_cont',Pipeline([\n",
    "                                ('extract',ColumnExtractor(cont_cols)),\n",
    "                                ('poly',PolynomialFeatures(degree=3)),\n",
    "                                ('kpca',KernelPCA())#,\n",
    "#                                 ('kbest',SelectKBest(10))\n",
    "                                            ])),\n",
    "#                           ('f_cat',Pipeline([\n",
    "#                                 ('extract',ColumnExtractor(cat_cols)),\n",
    "#                                 ('dummies',GetDummies())]))\n",
    "                           ])),\n",
    "#                      ('estimators',FeatureUnion([\n",
    "#                             ('svm',ModelTransformer(SVC(C=1.0,gamma=0.1,kernel='rbf',random_state=1))),\n",
    "#                             ('knn',ModelTransformer(KNeighborsClassifier(weights='uniform',\n",
    "#                                                            n_neighbors=8))),\n",
    "#                             ('rfc',ModelTransformer(RandomForestClassifier(min_samples_split=10,\n",
    "#                                                            criterion='entropy',\n",
    "#                                                            max_features=4,\n",
    "#                                                            n_estimators=20,\n",
    "#                                                            random_state=1))),\n",
    "#                             ('lrc',ModelTransformer(LogisticRegression(solver = 'newton-cg',\n",
    "#                                                            class_weight = None,\n",
    "#                                                            penalty = 'l2',\n",
    "#                                                            C = 100.0,\n",
    "#                                                            random_state=1)))\n",
    "#                             ])),\n",
    "                     ('clf',SVC())#C=1.0,gamma=0.1,kernel='rbf',random_state=1))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KernelPCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "param_grid = [{'features__f_cont__kpca__kernel': [\"linear\",\"poly\",\"rbf\"],\n",
    "               'features__f_cont__kpca__degree': [2,3,4],\n",
    "               'features__f_cont__poly__degree':[2,3],\n",
    "               'clf__C': param_range,\n",
    "               'clf__kernel': ['linear','rbf']}]\n",
    "# ,\n",
    "#               {'features__f_cont__poly__degree':[2,3],\n",
    "#                'clf__C': param_range,\n",
    "#                'clf__gamma': param_range,\n",
    "#                'clf__kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_big,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=4,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 252 candidates, totalling 1008 fits\n",
      "0.765498652291\n",
      "{'features__f_cont__poly__degree': 2, 'features__f_cont__kpca__kernel': 'rbf', 'clf__C': 10.0, 'features__f_cont__kpca__degree': 2, 'clf__kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1008 out of 1008 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "gs.fit(train.drop(['id'],axis=1),train.type.values)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765303203661 0.0146433813717\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(gs.best_estimator_, train, train.type.values,cv=4)\n",
    "print(scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = gs.best_estimator_.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission3 = pd.DataFrame({'id':test.id.values,'type':pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     507\n",
       "False     22\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(submission2.type == submission3.type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is essentially the same as submission3 except with KPCA set to default values\n",
    "submission2.to_csv('ghouls_big_pipe.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the big pipe with KPCA as part of the grid search\n",
    "submission3.to_csv('ghouls_big_pipe02.csv',index=False)\n",
    "\n",
    "# although 22 values here are different than before - it received the same score as submission3 0.74291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
